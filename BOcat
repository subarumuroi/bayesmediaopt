"""Hybrid kernel"""

import torch
from botorch.models.kernels import MaternKernel, ScaleKernel
from gpytorch.kernels import Kernel
from gpytorch.constraints import Interval

class CategoricalKernel(Kernel):
    """Kernel for categorical variables using a similarity matrix."""
    
    def __init__(self, similarity_matrix, **kwargs):
        super().__init__(**kwargs)
        self.similarity_matrix = similarity_matrix

    def forward(self, x1, x2, diag=False, **params):
        x1, x2 = x1.long().squeeze(), x2.long().squeeze()
        return self.similarity_matrix[x1, x2]

# Define similarity matrix for categorical variables (example: 3 categories)
similarity_matrix = torch.tensor([
    [1.0, 0.5, 0.2],
    [0.5, 1.0, 0.3],
    [0.2, 0.3, 1.0],
])

# Instantiate kernels
cat_kernel = CategoricalKernel(similarity_matrix)
cont_kernel = ScaleKernel(MaternKernel(nu=2.5))

class HybridKernel(Kernel):
    """Kernel combining continuous and categorical variables."""

    def __init__(self, cont_kernel, cat_kernel, **kwargs):
        super().__init__(**kwargs)
        self.cont_kernel = cont_kernel
        self.cat_kernel = cat_kernel
        self.lambda_param = torch.nn.Parameter(torch.tensor(0.5), requires_grad=True)
        self.register_constraint("lambda_param", Interval(0.0, 1.0))

    def forward(self, x1, x2, diag=False, **params):
        x1_cont, x1_cat = x1[:, :-1], x1[:, -1]
        x2_cont, x2_cat = x2[:, :-1], x2[:, -1]
        k_x = self.cont_kernel(x1_cont, x2_cont, diag=diag, **params)
        k_h = self.cat_kernel(x1_cat, x2_cat, diag=diag, **params)
        return self.lambda_param * k_x + (1 - self.lambda_param) * k_h




""" GP Model for Batch CoCaBO """

from botorch.models import SingleTaskGP
from gpytorch.likelihoods import GaussianLikelihood
from gpytorch.mlls import ExactMarginalLogLikelihood

# Example training data: 2 continuous + 1 categorical (last column)
train_x = torch.tensor([
    [0.1, 1.2, 0],
    [0.5, 2.3, 1],
    [0.9, 3.5, 2],
])
train_y = torch.tensor([0.2, 0.8, 1.5])

# Define Gaussian Process model
likelihood = GaussianLikelihood()
model = SingleTaskGP(train_x, train_y.unsqueeze(-1), likelihood=likelihood)

# Assign Hybrid Kernel
model.covar_module = HybridKernel(cont_kernel, cat_kernel)

# Train model
mll = ExactMarginalLogLikelihood(model.likelihood, model)




""" MAB for categorical selection """

import numpy as np

class ThompsonSamplingMAB:
    """Multi-Armed Bandit using Thompson Sampling."""
    
    def __init__(self, n_arms):
        self.n_arms = n_arms
        self.alpha = np.ones(n_arms)
        self.beta = np.ones(n_arms)

    def select_arm(self):
        """Selects an arm based on Thompson Sampling."""
        sampled_values = np.random.beta(self.alpha, self.beta)
        return np.argmax(sampled_values)

    def update(self, arm, reward):
        """Updates posterior distributions based on observed reward."""
        self.alpha[arm] += reward
        self.beta[arm] += (1 - reward)

# Example: 3 categorical choices
mab = ThompsonSamplingMAB(n_arms=3)

# Select best categorical option
selected_arm = mab.select_arm()



""" Bayesian Optimization with Batch Selection """

from botorch.optim.optimize import optimize_acqf
from botorch.acquisition import UpperConfidenceBound

# Define UCB acquisition function
acq_func = UpperConfidenceBound(model, beta=2.0)

# Optimize acquisition function to get batch suggestions
bounds = torch.tensor([[0.0, 0.0, 0], [1.0, 5.0, 2]])  # Adjust for problem
batch_candidates, acq_values = optimize_acqf(acq_func, bounds=bounds, q=3, num_restarts=5, raw_samples=20)

print("Suggested batch points:", batch_candidates)




