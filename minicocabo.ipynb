{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini CoCaBO. Adapted from Ru's CoCaBO.\n",
    "\n",
    "# Author: Subaru\n",
    "\n",
    "# 1 Define the problem domain, or the data structure we want to fit the model onto.\n",
    "\n",
    "'''\n",
    "# this is currently unknown, but defined here to integrate with code\n",
    "# f = function GPR model, but can't be created without the experimental results\n",
    "'''\n",
    "#this list denotes the number of discrete variables under each categorical variable\n",
    "categories = [2, 3] # first cateogory hsa 2 values, second has 3 values\n",
    "\n",
    "C = categories\n",
    "\n",
    "# below categoricals have to be congrusent with above \n",
    "bounds = [\n",
    "    {'name': 'h1', 'type': 'categorical', 'domain': (0, 1)}, # 2 values\n",
    "    {'name': 'h2', 'type': 'categorical', 'domain': (0, 1, 2)}, # 3 values\n",
    "    {'name': 'x1', 'type': 'continuous', 'domain': (-1, 1)}, # define bounds for continuous variables\n",
    "    {'name': 'x2', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "    {'name': 'x3', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "    {'name': 'x4', 'type': 'continuous', 'domain': (-1, 1)}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    h1   h2        x1        x2        x3        x4\n",
      "0  0.0  2.0 -0.561729  0.424159  0.416662  0.614814\n",
      "1  0.0  1.0  0.968700 -0.231780 -0.456543  0.338718\n",
      "2  1.0  2.0  0.492801 -0.071257  0.274009 -0.802539\n",
      "3  0.0  2.0  0.319719 -0.949339  0.806108  0.051825\n",
      "4  0.0  1.0 -0.667612 -0.577574 -0.297410  0.474079\n",
      "5  1.0  2.0  0.010305  0.791323  0.181799 -0.298815\n",
      "6  0.0  1.0 -0.124414  0.887285 -0.033701  0.847615\n",
      "7  1.0  2.0  0.649020  0.373001  0.790293 -0.160773\n",
      "8  0.0  1.0 -0.986401 -0.613304 -0.637784 -0.792919\n",
      "9  0.0  0.0 -0.318134  0.069725 -0.920371 -0.594758\n",
      "[array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0]), array([2, 1, 2, 2, 1, 2, 1, 2, 1, 0])]\n",
      "[[-0.56172898  0.42415907  0.41666228  0.61481382]\n",
      " [ 0.96870036 -0.23178036 -0.45654338  0.33871791]\n",
      " [ 0.49280147 -0.07125669  0.27400891 -0.80253891]\n",
      " [ 0.31971886 -0.94933853  0.80610825  0.05182498]\n",
      " [-0.66761246 -0.57757413 -0.29740959  0.47407899]\n",
      " [ 0.01030549  0.79132341  0.18179871 -0.29881527]\n",
      " [-0.12441381  0.88728535 -0.03370062  0.8476148 ]\n",
      " [ 0.64901951  0.37300091  0.79029298 -0.1607726 ]\n",
      " [-0.98640078 -0.61330447 -0.63778395 -0.79291915]\n",
      " [-0.31813429  0.06972492 -0.9203714  -0.5947575 ]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have your data as raw lab results:\n",
    "# Sample data for demonstration (replace with actual data from lab)\n",
    "# Categorical variables: randomly generate indices based on the domains\n",
    "# Continuous variables: uses Latin Hypercube Sampling (LHS) to generate samples\n",
    "# LHS is a statistical method for generating a distribution of samples of parameter values from a multidimensional distribution.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyDOE import lhs\n",
    "\n",
    "\n",
    "# Number of samples to generate\n",
    "n_samples = 10\n",
    "random_seed =42\n",
    "np.random.seed = random_seed\n",
    "\n",
    "# Generate Latin Hypercube Samples for continuous variables\n",
    "n_continuous = len(bounds) - len(categories)  # Continuous variables come after categorical ones\n",
    "continuous_bounds = [b['domain'] for b in bounds[len(categories):]]\n",
    "\n",
    "# Initialize LHS for continuous variables\n",
    "lhs_samples = lhs(n_continuous, samples=n_samples)\n",
    "\n",
    "# Map LHS samples to the continuous variables' bounds\n",
    "continuous_data = np.zeros((n_samples, n_continuous))\n",
    "for i, (lower, upper) in enumerate(continuous_bounds):\n",
    "    continuous_data[:, i] = lhs_samples[:, i] * (upper - lower) + lower\n",
    "\n",
    "# Generate categorical data using LHS-style sampling\n",
    "categorical_data = []\n",
    "for i, cat in enumerate(categories):\n",
    "    categorical_data.append(np.random.choice(range(cat), size=n_samples))\n",
    "\n",
    "# Combine categorical and continuous data into a single data set\n",
    "data = np.column_stack(categorical_data + [continuous_data[:, i] for i in range(n_continuous)])\n",
    "\n",
    "# Convert to pandas DataFrame for easy manipulation\n",
    "columns = [b['name'] for b in bounds]  # Extract column names (variable names)\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Print the generated DataFrame\n",
    "print(df)\n",
    "print(categorical_data)\n",
    "print(continuous_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    h1   h2        x1        x2        x3        x4          y\n",
      "0  0.0  2.0 -0.561729  0.424159  0.416662  0.614814  12.331591\n",
      "1  0.0  1.0  0.968700 -0.231780 -0.456543  0.338718   7.675713\n",
      "2  1.0  2.0  0.492801 -0.071257  0.274009 -0.802539  19.704807\n",
      "3  0.0  2.0  0.319719 -0.949339  0.806108  0.051825  17.022005\n",
      "4  0.0  1.0 -0.667612 -0.577574 -0.297410  0.474079   6.471065\n",
      "5  1.0  2.0  0.010305  0.791323  0.181799 -0.298815  17.800944\n",
      "6  0.0  1.0 -0.124414  0.887285 -0.033701  0.847615   8.884543\n",
      "7  1.0  2.0  0.649020  0.373001  0.790293 -0.160773  21.941324\n",
      "8  0.0  1.0 -0.986401 -0.613304 -0.637784 -0.792919  14.840257\n",
      "9  0.0  0.0 -0.318134  0.069725 -0.920371 -0.594758   3.014855\n"
     ]
    }
   ],
   "source": [
    "# Define the fake objective function\n",
    "def fake_objective_function(ht_list, X):\n",
    "    \"\"\"A simple quadratic function for testing purposes\"\"\"\n",
    "    return np.sum(np.square(X)) + np.sum(ht_list)  # Just an example\n",
    "\n",
    "# Create the y values (response) for each row\n",
    "y_values = np.array([fake_objective_function(list(df.iloc[i, :len(categories)]), df.iloc[i, len(categories):]) for i in range(len(df))])\n",
    "\n",
    "df1 = df\n",
    "# Add the fake y values as a new column to the dataframe\n",
    "df1['y'] = y_values\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# These definitions outside class are utility functions placed here, so it's all in one place.\n",
    "def with_proba(epsilon):\n",
    "        \"\"\"Bernoulli test: Returns True with probability epsilon, otherwise False.\"\"\"\n",
    "        assert 0 <= epsilon <= 1, \"epsilon must be between 0 and 1\"\n",
    "        return random.random() < epsilon\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created based on\n",
    "https://jeremykun.com/2013/11/08/adversarial-bandits-and-the-exp3-algorithm/\n",
    "\"\"\"\n",
    "# draw: [float] -> int\n",
    "# pick an index from the given list of floats proportionally\n",
    "# to the size of the entry (i.e. normalize to a probability\n",
    "# distribution and draw according to the probabilities).\n",
    "def draw(weights):\n",
    "    choice = random.uniform(0, sum(weights))\n",
    "    #    print(choice)\n",
    "    choiceIndex = 0\n",
    "\n",
    "    for weight in weights:\n",
    "        choice -= weight\n",
    "        if choice <= 0:\n",
    "            return choiceIndex\n",
    "        choiceIndex += 1\n",
    "\n",
    "# distr: [float] -> (float)\n",
    "# Normalize a list of floats to a probability distribution.  Gamma is an\n",
    "# egalitarianism factor, which tempers the distribtuion toward being uniform as\n",
    "# it grows from zero to one.\n",
    "def distr(weights, gamma=0.0):\n",
    "    theSum = float(sum(weights))\n",
    "    return tuple((1.0 - gamma) * (w / theSum) + (gamma / len(weights)) for w in weights)\n",
    "\n",
    "def DepRound(weights_p, k=1, isWeights=True):\n",
    "    r\"\"\" [[Algorithms for adversarial bandit problems with multiple plays, by T.Uchiya, A.Nakamura and M.Kudo, 2010](http://hdl.handle.net/2115/47057)] Figure 5 (page 15) is a very clean presentation of the algorithm.\n",
    "\n",
    "    - Inputs: :math:`k < K` and weights_p :math:`= (p_1, \\dots, p_K)` such that :math:`\\sum_{i=1}^{K} p_i = k` (or :math:`= 1`).\n",
    "    - Output: A subset of :math:`\\{1,\\dots,K\\}` with exactly :math:`k` elements. Each action :math:`i` is selected with probability exactly :math:`p_i`.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    >>> import numpy as np; import random\n",
    "    >>> np.random.seed(0); random.seed(0)  # for reproductibility!\n",
    "    >>> K = 5\n",
    "    >>> k = 2\n",
    "\n",
    "    >>> weights_p = [ 2, 2, 2, 2, 2 ]  # all equal weights\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [3, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [3, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 1]\n",
    "\n",
    "    >>> weights_p = [ 10, 8, 6, 4, 2 ]  # decreasing weights\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [1, 2]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [3, 4]\n",
    "\n",
    "    >>> weights_p = [ 3, 3, 0, 0, 3 ]  # decreasing weights\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 4]\n",
    "    >>> DepRound(weights_p, k)\n",
    "    [0, 1]\n",
    "\n",
    "    - See [[Gandhi et al, 2006](http://dl.acm.org/citation.cfm?id=1147956)] for the details.\n",
    "    \"\"\"\n",
    "    p = np.array(weights_p)\n",
    "    K = len(p)\n",
    "    # Checks\n",
    "    assert k < K, f\"Error: k = {k} should be < K = {K}.\"  # DEBUG\n",
    "    if not np.isclose(np.sum(p), 1):\n",
    "        p = p / np.sum(p)\n",
    "    assert np.all(0 <= p) and np.all(p <= 1), f\"Error: the weights (p_1, ..., p_K) should all be 0 <= p_i <= 1. Got {p}\"  # DEBUG\n",
    "    assert np.isclose(np.sum(p), 1), f\"Error: the sum of weights p_1 + ... + p_K should =1. Got: {np.sum(p)}\"  # DEBUG\n",
    "    # Main loop\n",
    "    possible_ij = [a for a in range(K) if 0 < p[a] < 1]\n",
    "    while possible_ij:\n",
    "        # Choose distinct i, j with 0 < p_i, p_j < 1\n",
    "        if len(possible_ij) == 1:\n",
    "            i = np.random.choice(possible_ij, size=1)\n",
    "            j = i\n",
    "        else:\n",
    "            i, j = np.random.choice(possible_ij, size=2, replace=False)\n",
    "        pi, pj = p[i], p[j]\n",
    "        assert 0 <= pi <= 1, f\"Error: pi = {pi} (with i = {i}) is not 0 <= pi <= 1.\"  # DEBUG\n",
    "        assert 0 <= pj <= 1, f\"Error: pj = {pj} (with j = {j}) is not 0 <= pj <= 1.\"  # DEBUG\n",
    "        assert i != j, f\"Error: i = {i} is different than with j = {j}.\" # DEBUG\n",
    "\n",
    "        # Set alpha, beta\n",
    "        alpha, beta = min(1 - pi, pj), min(pi, 1 - pj)\n",
    "        proba = alpha / (alpha + beta)\n",
    "        if with_proba(proba):  # with probability = proba = alpha/(alpha+beta)\n",
    "            pi, pj = pi + alpha, pj - alpha\n",
    "        else:            # with probability = 1 - proba = beta/(alpha+beta)\n",
    "            pi, pj = pi - beta, pj + beta\n",
    "\n",
    "        # Store\n",
    "        p[i], p[j] = pi, pj\n",
    "        # And update\n",
    "        possible_ij = [a for a in range(K) if 0 < p[a] < 1]\n",
    "        if len([a for a in range(K) if np.isclose(p[a], 0)]) == K - k:\n",
    "            break\n",
    "    # Final step\n",
    "    subset = [a for a in range(K) if np.isclose(p[a], 1)]\n",
    "    if len(subset) < k:\n",
    "        subset = [a for a in range(K) if not np.isclose(p[a], 0)]\n",
    "    assert len(subset) == k, f\"Error: DepRound({weights_p}, {k}) is supposed to return a set of size {k}, but {subset} has size {len(subset)}...\" # DEBUG\n",
    "    return subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed for draw function.\n"
     ]
    }
   ],
   "source": [
    "def test_draw():\n",
    "    weights = [1, 2, 3]\n",
    "    result = draw(weights)\n",
    "    assert result in [0, 1, 2], f\"Test failed. Result was: {result}\"\n",
    "    print(\"Test passed for draw function.\")\n",
    "\n",
    "test_draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed for distr function.\n"
     ]
    }
   ],
   "source": [
    "def test_distr():\n",
    "    weights = [2, 2, 2]\n",
    "    result = distr(weights)\n",
    "    assert sum(result) == 1.0, f\"Test failed. Sum of probabilities is: {sum(result)}\"\n",
    "    assert all(0 <= x <= 1 for x in result), f\"Test failed. Result contains out-of-bound values: {result}\"\n",
    "    print(\"Test passed for distr function.\")\n",
    "\n",
    "test_distr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed for DepRound function. Result: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "def test_depround():\n",
    "    weights_p = [2, 2, 2, 2, 2]\n",
    "    k = 2\n",
    "    result = DepRound(weights_p, k)\n",
    "    assert len(result) == k, f\"Test failed. Expected subset of size {k}, but got {len(result)}\"\n",
    "    print(f\"Test passed for DepRound function. Result: {result}\")\n",
    "\n",
    "test_depround()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed for with_proba function.\n"
     ]
    }
   ],
   "source": [
    "def test_with_proba():\n",
    "    prob = 0.7\n",
    "    result = with_proba(prob)\n",
    "    assert result in [True, False], f\"Test failed. Result was: {result}\"\n",
    "    print(\"Test passed for with_proba function.\")\n",
    "\n",
    "test_with_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "class miniCoCaBO(): # combining baseBO and CoCaBO_base from Ru\n",
    "\n",
    "     # Ru BaseBO and CoCaBO_base __init__  \n",
    "    def __init__(self, objfn, initN, bounds, C, \n",
    "                  acq_type, kernel_mix=0.5, mix_lr=10, \n",
    "                  model_update_interval =10,\n",
    "                  ard=False, rand_seed=42, debug=False,\n",
    "                  batch_size=1, **kwargs):\n",
    "        self.f = objfn  # function to optimise\n",
    "        self.bounds = bounds  # function bounds\n",
    "        self.batch_size = batch_size\n",
    "        self.C = C  # no of categories\n",
    "        self.C_list = C # Ensure compatibility with existing functions\n",
    "        self.initN = initN  # no: of initial points\n",
    "        self.nDim = len(self.bounds)  # dimension\n",
    "        self.acq_type = acq_type # Acquisition function type\n",
    "        self.rand_seed = rand_seed\n",
    "        self.debug = debug\n",
    "        self.saving_path = None\n",
    "        self.kwargs = kwargs\n",
    "        self.best_val_list =[]\n",
    "\n",
    "        self.x_bounds = np.vstack([d['domain'] for d in self.bounds\n",
    "                                   if d['type'] == 'continuous'])\n",
    "\n",
    "        # Store the ht recommendations for each iteration\n",
    "        self.ht_recommendations = []\n",
    "        self.ht_hist_batch = []\n",
    "\n",
    "        '''\n",
    "        # Store the name of the alogrithm'\n",
    "        self. policy = None'\n",
    "        '''\n",
    "\n",
    "        self.X=[]\n",
    "        self.Y=[]\n",
    "\n",
    "        # To check the best vals\n",
    "        self.gp_bestvals = []\n",
    "        self.ARD = ard\n",
    "\n",
    "        # Keeping track of current interation helps control mix learning\n",
    "        self.iteration = None\n",
    "\n",
    "        self.model_hp = None\n",
    "        self.default_cont_lengthscale = 0.2\n",
    "\n",
    "        self.mix = kernel_mix\n",
    "\n",
    "        if ((model_update_interval % mix_lr ==0) or (mix_lr % model_update_interval ==0)):\n",
    "            self.mix_learn_rate = mix_lr\n",
    "            self.model_update_interval = model_update_interval\n",
    "        else:\n",
    "            self.mix_learn_rate = min(mix_lr, model_update_interval)\n",
    "            self.model_update_interval = min(mix_lr, model_update_interval)\n",
    "        self.mix_used = 0.5\n",
    "\n",
    "        self.name = \"miniCoCaBO\"\n",
    "\n",
    "     #Ru BaseBO function   \n",
    "    def my_func(self, Z):\n",
    "        Z = np.atleast_2d(Z)\n",
    "        if len(Z) == 1:\n",
    "            X = Z[0, len(self.C):]\n",
    "            ht_list = list(Z[0, :len(self.C)])\n",
    "            return self.f(ht_list, X)\n",
    "        else:\n",
    "            f_vals = np.zeros(len(Z))\n",
    "            for ii in range(len(Z)):\n",
    "                X = Z[ii, len(self.C):]\n",
    "                ht_list = list(Z[ii, :len(self.C)].astype(int))\n",
    "                f_vals[ii] = self.f(ht_list, X)\n",
    "            return f_vals \n",
    "    \n",
    "\n",
    "    # Ru CoCaBO_base function This functions controls how categorical weights (Wc) \n",
    "    # are updated. If a certain category is overrepresented alpha reduces their dominance\n",
    "    # and if a certain category is underrepresented alpha increases their probability of being selected\n",
    "    # in the next iteration. This is controled by the gamma parameter. \n",
    "\n",
    "    # Large gamma = explore, small gamma = exploit\n",
    "    def estimate_alpha(self, batch_size, gamma, Wc, C):\n",
    "\n",
    "        def single_evaluation(alpha):\n",
    "            denominator = sum([alpha if val > alpha else val for idx, val in enumerate(Wc)])\n",
    "            rightside = (1 / batch_size - gamma / C) / (1 - gamma)\n",
    "            output = np.abs(alpha / denominator - rightside)\n",
    "\n",
    "            return output\n",
    "\n",
    "        x_tries = np.random.uniform(0, np.max(Wc), size=(100, 1))\n",
    "        y_tries = [single_evaluation(val) for val in x_tries]\n",
    "        # find x optimal for init\n",
    "        # print(f'ytry_len={len(y_tries)}')\n",
    "        idx_min = np.argmin(y_tries)\n",
    "        x_init_min = x_tries[idx_min]\n",
    "\n",
    "        res = minimize(single_evaluation, x_init_min, method='BFGS', options={'gtol': 1e-6, 'disp': False})\n",
    "        if isinstance(res, float):\n",
    "            return res\n",
    "        else:\n",
    "            return res.x\n",
    "    # Ru CoCaBO_base function\n",
    "    def compute_reward_for_all_cat_variable(self, ht_next_batch_list, batch_size):\n",
    "        # Obtain the reward for each categorical variable: B x len(self.C_list)\n",
    "        ht_batch_list_rewards = np.zeros((batch_size, len(self.C_list)))\n",
    "        for b in range(batch_size):\n",
    "            ht_next_list = ht_next_batch_list[b, :]\n",
    "\n",
    "            for i in range(len(ht_next_list)):\n",
    "                idices = np.where(self.data[0][:, i] == ht_next_list[i])\n",
    "                ht_result = self.result[0][idices]\n",
    "                ht_reward = np.max(ht_result * -1)\n",
    "                ht_batch_list_rewards[b, i] = ht_reward\n",
    "        return ht_batch_list_rewards\n",
    "    # Ru CoCaBO_base function\n",
    "    def update_weights_for_all_cat_var(self, Gt_ht_list, ht_batch_list, Wc_list, gamma_list,\n",
    "                                        probabilityDistribution_list, batch_size, S0=None):\n",
    "        for j in range(len(self.C_list)):\n",
    "            Wc = Wc_list[j]\n",
    "            C = self.C_list[j]\n",
    "            gamma = gamma_list[j]\n",
    "            probabilityDistribution = probabilityDistribution_list[j]\n",
    "            # print(f'cat_var={j}, prob={probabilityDistribution}')\n",
    "\n",
    "            if batch_size > 1:\n",
    "                ht_batch_list = ht_batch_list.astype(int)\n",
    "                Gt_ht = Gt_ht_list[:, j]\n",
    "                mybatch_ht = ht_batch_list[:, j]  # 1xB\n",
    "                for ii, ht in enumerate(mybatch_ht):\n",
    "                    Gt_ht_b = Gt_ht[ii]\n",
    "                    estimatedReward = 1.0 * Gt_ht_b / probabilityDistribution[ht]\n",
    "                    if ht not in S0:\n",
    "                        Wc[ht] *= np.exp(batch_size * estimatedReward * gamma / C)\n",
    "            else:\n",
    "                Gt_ht = Gt_ht_list[j]\n",
    "                ht = ht_batch_list[j]  # 1xB\n",
    "                estimatedReward = 1.0 * Gt_ht / probabilityDistribution[ht]\n",
    "                Wc[ht] *= np.exp(estimatedReward * gamma / C)\n",
    "\n",
    "        return Wc_list\n",
    "    # Ru CoCaBO_base function\n",
    "    def compute_prob_dist_and_draw_hts(self, Wc_list, gamma_list, batch_size):\n",
    "\n",
    "        if batch_size > 1:\n",
    "            ht_batch_list = np.zeros((batch_size, len(self.C_list)))\n",
    "            probabilityDistribution_list = []\n",
    "\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                C = self.C_list[j]\n",
    "                # perform some truncation here\n",
    "                maxW = np.max(Wc)\n",
    "                temp = np.sum(Wc) * (1.0 / batch_size - gamma / C) / (1 - gamma)\n",
    "                if gamma < 1 and maxW >= temp:\n",
    "                    # find a threshold alpha\n",
    "                    alpha = self.estimate_alpha(batch_size, gamma, Wc, C)\n",
    "                    S0 = [idx for idx, val in enumerate(Wc) if val > alpha]\n",
    "                else:\n",
    "                    S0 = []\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "\n",
    "                # draw a batch here\n",
    "                if batch_size < C:\n",
    "                    mybatch_ht = DepRound(probabilityDistribution, k=batch_size)\n",
    "                else:\n",
    "                    mybatch_ht = np.random.choice(len(probabilityDistribution), batch_size, p=probabilityDistribution)\n",
    "\n",
    "                # ht_batch_list size: len(self.C_list) x B\n",
    "                ht_batch_list[:, j] = mybatch_ht[:]\n",
    "\n",
    "                # ht_batch_list.append(mybatch_ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_batch_list, probabilityDistribution_list, S0\n",
    "\n",
    "        else:\n",
    "            ht_list = []\n",
    "            probabilityDistribution_list = []\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "                # Choose a categorical variable at random\n",
    "                ht = draw(probabilityDistribution)\n",
    "                ht_list.append(ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_list, probabilityDistribution_list\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
