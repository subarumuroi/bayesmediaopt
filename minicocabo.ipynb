{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini CoCaBO. Adapted from Ru's CoCaBO.\n",
    "\n",
    "# Author: Subaru\n",
    "\n",
    "# 1 Define the problem domain, or the data structure we want to fit the model onto.\n",
    "\n",
    "# this is currently unknown, but defined here to integrate with code\n",
    "\n",
    "'''\n",
    "# f = function (this is probably dataset for training purposes)\n",
    "'''\n",
    "#this list denotes the number of discrete variables under each categorical variable\n",
    "categories = [2, 3] # first cateogory hsa 2 values, second has 3 values\n",
    "\n",
    "C = categories\n",
    "\n",
    "# below categoricals have to be congrusent with above \n",
    "bounds = [{'name': 'h1', 'type': 'categorical', 'domain': (0, 1)}, # 2 values\n",
    "    {'name': 'h2', 'type': 'categorical', 'domain': (0, 1, 2)}, # 3 values\n",
    "    {'name': 'x1', 'type': 'continuous', 'domain': (-1, 1)}, # define bounds for continuous variables\n",
    "    {'name': 'x2', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "    {'name': 'x3', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "    {'name': 'x4', 'type': 'continuous', 'domain': (-1, 1)}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 129)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:129\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef update_weights_for_all_cat_var(self, Gt_ht_list, ht_batch_list, Wc_list, gamma_list,\u001b[39m\n                                                                                            ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class miniCoCaBO(): # combining baseBO and CoCaBO_base from Ru\n",
    "\n",
    "     # Ru BaseBO and CoCaBO_base __init__  \n",
    "    def __init__(self, objfn, initN, bounds, C, \n",
    "                  acq_type, kernel_mix=0.5, mix_lr=10, \n",
    "                  model_update_interval =10,\n",
    "                  ard=False, rand_seed=42, debug=False,\n",
    "                  batch_size=1, **kwargs):\n",
    "        self.f = objfn  # function to optimise\n",
    "        self.bounds = bounds  # function bounds\n",
    "        self.batch_size = batch_size\n",
    "        self.C = C  # no of categories\n",
    "        self.initN = initN  # no: of initial points\n",
    "        self.nDim = len(self.bounds)  # dimension\n",
    "        self.acq_type = acq_type # Acquisition function type\n",
    "        self.rand_seed = rand_seed\n",
    "        self.debug = debug\n",
    "        self.saving_path = None\n",
    "        self.kwargs = kwargs\n",
    "        self.x_bounds = np.vstack([d['domain'] for d in self.bounds\n",
    "                                   if d['type'] == 'continuous'])\n",
    "\n",
    "        # Store the ht recommendations for each iteration\n",
    "        self.ht_recommendations = []\n",
    "        self.ht_hist_batch = []\n",
    "\n",
    "        '''\n",
    "        # Store the name of the alogrithm'\n",
    "        self. policy = None'\n",
    "        '''\n",
    "\n",
    "        self.X=[]\n",
    "        self.Y=[]\n",
    "\n",
    "        # To check the best vals\n",
    "        self.gp_bestvals = []\n",
    "        self.ARD = ard\n",
    "\n",
    "        # Keeping track of current interation helps control mix learning\n",
    "        self.iteration = None\n",
    "\n",
    "        self.model_hp = None\n",
    "        self.default_cont_lengthscale = 0.2\n",
    "\n",
    "        self.mix = kernel_mix\n",
    "\n",
    "        if ((model_update_interval % mix_lr ==0) or (mix_lr % model_update_interval ==0)):\n",
    "            self.mix_learn_rate = mix_lr\n",
    "            self.model_update_interval = model_update_interval\n",
    "        else:\n",
    "            self.mix_learn_rate = min(mix_lr, model_update_interval)\n",
    "            self.model_update_interval = min(mix_lr, model_update_interval)\n",
    "        self.mix_used = 0.5\n",
    "\n",
    "        self.name = None\n",
    "\n",
    "     #Ru BaseBO function   \n",
    "    def my_func(self, Z):\n",
    "        Z = np.atleast_2d(Z)\n",
    "        if len(Z) == 1:\n",
    "            X = Z[0, len(self.C):]\n",
    "            ht_list = list(Z[0, :len(self.C)])\n",
    "            return self.f(ht_list, X)\n",
    "        else:\n",
    "            f_vals = np.zeros(len(Z))\n",
    "            for ii in range(len(Z)):\n",
    "                X = Z[ii, len(self.C):]\n",
    "                ht_list = list(Z[ii, :len(self.C)].astype(int))\n",
    "                f_vals[ii] = self.f(ht_list, X)\n",
    "            return f_vals\n",
    "        \n",
    "    # Ru CoCaBO_base function This functions controls how categorical weights (Wc) \n",
    "    # are updated. If a certain category is overrepresented alpha reduces their dominance\n",
    "    # and if a certain category is underrepresented alpha increases their probability of being selected\n",
    "    # in the next iteration. This is controled by the gamma parameter. \n",
    "\n",
    "    # Large gamma = explore, small gamma = exploit\n",
    "    def estimate_alpha(self, batch_size, gamma, Wc, C):\n",
    "\n",
    "        def single_evaluation(alpha):\n",
    "            denominator = sum([alpha if val > alpha else val for idx, val in enumerate(Wc)])\n",
    "            rightside = (1 / batch_size - gamma / C) / (1 - gamma)\n",
    "            output = np.abs(alpha / denominator - rightside)\n",
    "\n",
    "            return output\n",
    "\n",
    "        x_tries = np.random.uniform(0, np.max(Wc), size=(100, 1))\n",
    "        y_tries = [single_evaluation(val) for val in x_tries]\n",
    "        # find x optimal for init\n",
    "        # print(f'ytry_len={len(y_tries)}')\n",
    "        idx_min = np.argmin(y_tries)\n",
    "        x_init_min = x_tries[idx_min]\n",
    "\n",
    "        res = minimize(single_evaluation, x_init_min, method='BFGS', options={'gtol': 1e-6, 'disp': False})\n",
    "        if isinstance(res, float):\n",
    "            return res\n",
    "        else:\n",
    "            return res.x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_reward_for_all_cat_variable(self, ht_next_batch_list, batch_size):\n",
    "        # Obtain the reward for each categorical variable: B x len(self.C_list)\n",
    "        ht_batch_list_rewards = np.zeros((batch_size, len(self.C_list)))\n",
    "        for b in range(batch_size):\n",
    "            ht_next_list = ht_next_batch_list[b, :]\n",
    "\n",
    "            for i in range(len(ht_next_list)):\n",
    "                idices = np.where(self.data[0][:, i] == ht_next_list[i])\n",
    "                ht_result = self.result[0][idices]\n",
    "                ht_reward = np.max(ht_result * -1)\n",
    "                ht_batch_list_rewards[b, i] = ht_reward\n",
    "        return ht_batch_list_rewards\n",
    "\n",
    "    def update_weights_for_all_cat_var(self, Gt_ht_list, ht_batch_list, Wc_list, gamma_list,\n",
    "                                       probabilityDistribution_list, batch_size, S0=None):\n",
    "        for j in range(len(self.C_list)):\n",
    "            Wc = Wc_list[j]\n",
    "            C = self.C_list[j]\n",
    "            gamma = gamma_list[j]\n",
    "            probabilityDistribution = probabilityDistribution_list[j]\n",
    "            # print(f'cat_var={j}, prob={probabilityDistribution}')\n",
    "\n",
    "            if batch_size > 1:\n",
    "                ht_batch_list = ht_batch_list.astype(int)\n",
    "                Gt_ht = Gt_ht_list[:, j]\n",
    "                mybatch_ht = ht_batch_list[:, j]  # 1xB\n",
    "                for ii, ht in enumerate(mybatch_ht):\n",
    "                    Gt_ht_b = Gt_ht[ii]\n",
    "                    estimatedReward = 1.0 * Gt_ht_b / probabilityDistribution[ht]\n",
    "                    if ht not in S0:\n",
    "                        Wc[ht] *= np.exp(batch_size * estimatedReward * gamma / C)\n",
    "            else:\n",
    "                Gt_ht = Gt_ht_list[j]\n",
    "                ht = ht_batch_list[j]  # 1xB\n",
    "                estimatedReward = 1.0 * Gt_ht / probabilityDistribution[ht]\n",
    "                Wc[ht] *= np.exp(estimatedReward * gamma / C)\n",
    "\n",
    "        return Wc_list\n",
    "\n",
    "    def compute_prob_dist_and_draw_hts(self, Wc_list, gamma_list, batch_size):\n",
    "\n",
    "        if batch_size > 1:\n",
    "            ht_batch_list = np.zeros((batch_size, len(self.C_list)))\n",
    "            probabilityDistribution_list = []\n",
    "\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                C = self.C_list[j]\n",
    "                # perform some truncation here\n",
    "                maxW = np.max(Wc)\n",
    "                temp = np.sum(Wc) * (1.0 / batch_size - gamma / C) / (1 - gamma)\n",
    "                if gamma < 1 and maxW >= temp:\n",
    "                    # find a threshold alpha\n",
    "                    alpha = self.estimate_alpha(batch_size, gamma, Wc, C)\n",
    "                    S0 = [idx for idx, val in enumerate(Wc) if val > alpha]\n",
    "                else:\n",
    "                    S0 = []\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "\n",
    "                # draw a batch here\n",
    "                if batch_size < C:\n",
    "                    mybatch_ht = DepRound(probabilityDistribution, k=batch_size)\n",
    "                else:\n",
    "                    mybatch_ht = np.random.choice(len(probabilityDistribution), batch_size, p=probabilityDistribution)\n",
    "\n",
    "                # ht_batch_list size: len(self.C_list) x B\n",
    "                ht_batch_list[:, j] = mybatch_ht[:]\n",
    "\n",
    "                # ht_batch_list.append(mybatch_ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_batch_list, probabilityDistribution_list, S0\n",
    "\n",
    "        else:\n",
    "            ht_list = []\n",
    "            probabilityDistribution_list = []\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "                # Choose a categorical variable at random\n",
    "                ht = draw(probabilityDistribution)\n",
    "                ht_list.append(ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_list, probabilityDistribution_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
