{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to combine MultiArmBandit UCB into a Gaussian Process Regressor kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best continuous: [0.3], Best categorical: omic1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "class CoCaBO:\n",
    "    def __init__(self, continuous_dim, categorical_names, kernel=None, noise_var=1e-5):\n",
    "        \"\"\"\n",
    "        CoCaBO algorithm initialization\n",
    "        :param continuous_dim: Dimensionality of continuous variables\n",
    "        :param categorical_names: List of categorical names (e.g., ['omic1', 'omic2', ..., 'omic5'])\n",
    "        :param kernel: Kernel for the Gaussian Process (Matern kernel by default)\n",
    "        :param noise_var: Noise variance for Gaussian Process\n",
    "        \"\"\"\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.categorical_names = categorical_names\n",
    "        self.categorical_dim = len(categorical_names)  # Number of categorical arms\n",
    "        \n",
    "        # Initialize the kernel for Gaussian Process (Matern kernel)\n",
    "        self.kernel = kernel if kernel else Matern(length_scale=1.0, nu=1.5)  # Matern kernel with nu=1.5\n",
    "        \n",
    "        # Initialize the Gaussian Process Regressor\n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise_var)\n",
    "        \n",
    "        # Storage for past data\n",
    "        self.X_cont = []  # Stores continuous variables\n",
    "        self.X_cat = []   # Stores categorical variables (as indices)\n",
    "        self.y = []       # Stores corresponding objective function values\n",
    "        \n",
    "        # Initialize Multi-Armed Bandit (MAB) for categorical variable\n",
    "        self.mab_rewards = np.zeros(self.categorical_dim)  # Rewards for each categorical arm\n",
    "        self.mab_counts = np.zeros(self.categorical_dim)   # Count of pulls for each categorical arm\n",
    "    \n",
    "    def fit(self, X_cont, X_cat, y):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Process model on both continuous and categorical data.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param y: Objective function values (rewards)\n",
    "        \"\"\"\n",
    "        # Combine continuous and categorical data\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        \n",
    "        # Fit the Gaussian Process Regressor model\n",
    "        self.gpr.fit(X_combined, y)\n",
    "        \n",
    "        # Store the data for future optimization\n",
    "        self.X_cont.extend(X_cont)\n",
    "        self.X_cat.extend(X_cat)\n",
    "        self.y.extend(y)\n",
    "    \n",
    "    def predict(self, X_cont, X_cat):\n",
    "        \"\"\"\n",
    "        Predict mean and variance for new points.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :return: Mean and standard deviation from GP\n",
    "        \"\"\"\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        mean, std = self.gpr.predict(X_combined, return_std=True)\n",
    "        return mean, std\n",
    "    \n",
    "    def ucb(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound (UCB) acquisition function for continuous variables.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: UCB values\n",
    "        \"\"\"\n",
    "        mean, std = self.predict(X_cont, X_cat)\n",
    "        ucb_values = mean + kappa * std\n",
    "        return ucb_values\n",
    "    \n",
    "    def select_categorical_arm(self):\n",
    "        \"\"\"\n",
    "        Select the categorical arm using the best-performing arm (exploitation).\n",
    "        :return: Best categorical arm based on historical rewards\n",
    "        \"\"\"\n",
    "        # Select the categorical arm with the highest average reward\n",
    "        best_arm_idx = np.argmax(self.mab_rewards)\n",
    "        return self.categorical_names[best_arm_idx]  # Return the string name of the selected arm\n",
    "    \n",
    "    def update_mab(self, arm_idx, reward):\n",
    "        \"\"\"\n",
    "        Update the reward distribution of the Multi-Armed Bandit (MAB).\n",
    "        :param arm_idx: The index of the arm that was pulled\n",
    "        :param reward: The reward received for pulling the arm\n",
    "        \"\"\"\n",
    "        self.mab_counts[arm_idx] += 1\n",
    "        # Update the reward for the selected arm (simple average reward)\n",
    "        self.mab_rewards[arm_idx] = ((self.mab_counts[arm_idx] - 1) * self.mab_rewards[arm_idx] + reward) / self.mab_counts[arm_idx]\n",
    "    \n",
    "    def optimize(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Optimize the acquisition function (UCB) and select the best continuous and categorical values.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values\n",
    "        \"\"\"\n",
    "        # Select categorical arm using MAB (best-performing arm based on reward distribution)\n",
    "        h_t = self.select_categorical_arm()\n",
    "        # Convert the categorical arm name to its index\n",
    "        h_t_idx = self.categorical_names.index(h_t)\n",
    "        \n",
    "        # Optimize continuous variable using UCB\n",
    "        ucb_values = self.ucb(X_cont, np.full((X_cont.shape[0], 1), h_t_idx), kappa)\n",
    "        best_idx = np.argmax(ucb_values)  # Select the index with the highest UCB value\n",
    "        \n",
    "        # Return the best continuous and categorical pair (return categorical arm as string)\n",
    "        return X_cont[best_idx], h_t\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Categorical names as strings\n",
    "categorical_names = ['omic1', 'omic2', 'omic3', 'omic4', 'omic5']\n",
    "\n",
    "# Example continuous and categorical variables (encoded as indices for MAB)\n",
    "X_cont = np.array([[0.5], [0.2], [0.7]])  # Example continuous variables\n",
    "X_cat = np.array([[0], [1], [2]])  # Example categorical variables (as indices)\n",
    "y = np.array([0.3, 0.7, 0.5])  # Objective values (rewards)\n",
    "\n",
    "# Instantiate the CoCaBO object with categorical names and Matern kernel\n",
    "optimizer = CoCaBO(continuous_dim=1, categorical_names=categorical_names)\n",
    "\n",
    "# Fit the model to the data\n",
    "optimizer.fit(X_cont, X_cat, y)\n",
    "\n",
    "# Predict UCB values for new points\n",
    "new_cont = np.array([[0.6], [0.3]])  # New continuous points to evaluate\n",
    "new_cat = np.array([[1], [0]])  # New categorical points (encoded as indices)\n",
    "\n",
    "# Optimize to get the best combination of continuous and categorical variables\n",
    "best_cont, best_cat = optimizer.optimize(new_cont, new_cat)\n",
    "print(f\"Best continuous: {best_cont}, Best categorical: {best_cat}\")\n",
    "\n",
    "# Update MAB and fit with new data (simulating the query)\n",
    "best_cat_idx = categorical_names.index(best_cat)  # Convert the name back to an index\n",
    "optimizer.update_mab(best_cat_idx, reward=0.8)  # Update with new reward (simulated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something else, the last version I created.... I'm not really sure at this point but I need to go through it all cause the math is completely wrong at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: Best continuous: [0.78331689], Best categorical: omics1\n",
      "Prediction 2: Best continuous: [0.78331689], Best categorical: omics1\n",
      "Prediction 3: Best continuous: [0.78331689], Best categorical: omics1\n",
      "Prediction 4: Best continuous: [0.78331689], Best categorical: omics1\n",
      "Prediction 5: Best continuous: [0.78331689], Best categorical: omics1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "class CoCaBO:\n",
    "    def __init__(self, continuous_dim, categorical_names, kernel=None, noise_var=1e-5):\n",
    "        \"\"\"\n",
    "        CoCaBO algorithm initialization\n",
    "        :param continuous_dim: Dimensionality of continuous variables\n",
    "        :param categorical_names: List of categorical names (e.g., ['omic1', 'omic2', ..., 'omic5'])\n",
    "        :param kernel: Kernel for the Gaussian Process (Matern kernel by default)\n",
    "        :param noise_var: Noise variance for Gaussian Process\n",
    "        \"\"\"\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.categorical_names = categorical_names\n",
    "        self.categorical_dim = len(categorical_names)  # Number of categorical arms\n",
    "        \n",
    "        # Initialize the kernel for Gaussian Process (Matern kernel)\n",
    "        self.kernel = kernel if kernel else Matern(length_scale=1.0, nu=1.5)  # Matern kernel with nu=1.5\n",
    "        \n",
    "        # Initialize the Gaussian Process Regressor\n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise_var)\n",
    "        \n",
    "        # Storage for past data\n",
    "        self.X_cont = []  # Stores continuous variables\n",
    "        self.X_cat = []   # Stores categorical variables (as indices)\n",
    "        self.y = []       # Stores corresponding objective function values\n",
    "        \n",
    "        # Initialize Multi-Armed Bandit (MAB) for categorical variable\n",
    "        self.mab_rewards = np.zeros(self.categorical_dim)  # Rewards for each categorical arm\n",
    "        self.mab_counts = np.zeros(self.categorical_dim)   # Count of pulls for each categorical arm\n",
    "    \n",
    "    def fit(self, X_cont, X_cat, y):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Process model on both continuous and categorical data.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param y: Objective function values (rewards)\n",
    "        \"\"\"\n",
    "        # Combine continuous and categorical data\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        \n",
    "        # Fit the Gaussian Process Regressor model\n",
    "        self.gpr.fit(X_combined, y)\n",
    "        \n",
    "        # Store the data for future optimization\n",
    "        self.X_cont.extend(X_cont)\n",
    "        self.X_cat.extend(X_cat)\n",
    "        self.y.extend(y)\n",
    "    \n",
    "    def predict(self, X_cont, X_cat):\n",
    "        \"\"\"\n",
    "        Predict mean and variance for new points.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :return: Mean and standard deviation from GP\n",
    "        \"\"\"\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        mean, std = self.gpr.predict(X_combined, return_std=True)\n",
    "        return mean, std\n",
    "    \n",
    "    def ucb(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound (UCB) acquisition function for continuous variables.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: UCB values\n",
    "        \"\"\"\n",
    "        mean, std = self.predict(X_cont, X_cat)\n",
    "        ucb_values = mean + kappa * std\n",
    "        return ucb_values\n",
    "    \n",
    "    def select_categorical_arm(self):\n",
    "        \"\"\"\n",
    "        Select the categorical arm using the best-performing arm (exploitation).\n",
    "        :return: Best categorical arm based on historical rewards\n",
    "        \"\"\"\n",
    "        # Select the categorical arm with the highest average reward\n",
    "        best_arm_idx = np.argmax(self.mab_rewards)\n",
    "        return self.categorical_names[best_arm_idx]  # Return the string name of the selected arm\n",
    "    \n",
    "    def update_mab(self, arm_idx, reward):\n",
    "        \"\"\"\n",
    "        Update the reward distribution of the Multi-Armed Bandit (MAB).\n",
    "        :param arm_idx: The index of the arm that was pulled\n",
    "        :param reward: The reward received for pulling the arm\n",
    "        \"\"\"\n",
    "        self.mab_counts[arm_idx] += 1\n",
    "        # Update the reward for the selected arm (simple average reward)\n",
    "        self.mab_rewards[arm_idx] = ((self.mab_counts[arm_idx] - 1) * self.mab_rewards[arm_idx] + reward) / self.mab_counts[arm_idx]\n",
    "    \n",
    "    def optimize(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Optimize the acquisition function (UCB) and select the best continuous and categorical values.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values\n",
    "        \"\"\"\n",
    "        # Select categorical arm using MAB (best-performing arm based on reward distribution)\n",
    "        h_t = self.select_categorical_arm()\n",
    "        # Convert the categorical arm name to its index\n",
    "        h_t_idx = self.categorical_names.index(h_t)\n",
    "        \n",
    "        # Optimize continuous variable using UCB\n",
    "        ucb_values = self.ucb(X_cont, np.full((X_cont.shape[0], 1), h_t_idx), kappa)\n",
    "        best_idx = np.argmax(ucb_values)  # Select the index with the highest UCB value\n",
    "        \n",
    "        # Return the best continuous and categorical pair (return categorical arm as string)\n",
    "        return X_cont[best_idx], h_t\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Categorical names as strings\n",
    "categorical_names = ['omics1', 'omic2', 'omic2', 'omic4', 'omic5']\n",
    "\n",
    "# Generate a larger dataset (1000 points) for continuous and categorical variables\n",
    "X_cont = np.random.uniform(0, 1, (1000, 1))  # 1000 random continuous points in range [0, 1]\n",
    "X_cat = np.random.randint(0, 5, (1000, 1))  # 1000 random categorical points (encoded as indices)\n",
    "y = np.random.uniform(0, 1, 1000)  # Random objective function values between 0 and 1\n",
    "\n",
    "# Instantiate the CoCaBO object with categorical names and Matern kernel\n",
    "optimizer = CoCaBO(continuous_dim=1, categorical_names=categorical_names)\n",
    "\n",
    "# Fit the model to the larger dataset\n",
    "optimizer.fit(X_cont, X_cat, y)\n",
    "\n",
    "# Predict UCB values for new points (new continuous and categorical combinations)\n",
    "new_cont = np.random.uniform(0, 1, (5, 1))  # 5 new random continuous points to evaluate\n",
    "new_cat = np.random.randint(0, 5, (5, 1))  # 5 new random categorical points (encoded as indices)\n",
    "\n",
    "# Optimize to get the best combination of continuous and categorical variables\n",
    "for i in range(5):  # Simulate 5 predictions\n",
    "    best_cont, best_cat = optimizer.optimize(new_cont, new_cat)\n",
    "    print(f\"Prediction {i+1}: Best continuous: {best_cont}, Best categorical: {best_cat}\")\n",
    "\n",
    "    # Simulate a reward for this prediction and update the MAB and GP model\n",
    "    best_cat_idx = categorical_names.index(best_cat)  # Convert the name back to an index\n",
    "    reward = np.random.uniform(0, 1)  # Random reward between 0 and 1\n",
    "    optimizer.update_mab(best_cat_idx, reward)  # Update the model with new reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs fixing, but the below is attempting to use the liar's approach to use sequential predictions to generate a batch result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: Best continuous: [0.3], Best categorical: omic1, UCB value: 0.5025013626390963, Reward: 0.5993428306022466\n",
      "Prediction 2: Best continuous: [0.6], Best categorical: omic1, UCB value: 1.3976455652602264, Reward: 0.4723471397657631\n",
      "Prediction 3: Best continuous: [0.3], Best categorical: omic1, UCB value: 1.2828692572957117, Reward: 0.6295377076201385\n",
      "Prediction 4: Best continuous: [0.6], Best categorical: omic1, UCB value: 1.4249351250927602, Reward: 0.8046059712816052\n",
      "Prediction 5: Best continuous: [0.3], Best categorical: omic1, UCB value: 1.5831585168666864, Reward: 0.4531693250553328\n",
      "\n",
      "Predictions with UCB values:\n",
      "Best continuous: [0.3], Best categorical: omic1, UCB value: 0.5025013626390963\n",
      "Best continuous: [0.6], Best categorical: omic1, UCB value: 1.3976455652602264\n",
      "Best continuous: [0.3], Best categorical: omic1, UCB value: 1.2828692572957117\n",
      "Best continuous: [0.6], Best categorical: omic1, UCB value: 1.4249351250927602\n",
      "Best continuous: [0.3], Best categorical: omic1, UCB value: 1.5831585168666864\n",
      "\n",
      "Best continuous: [0.3], Best categorical: omic1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "class CoCaBO:\n",
    "    def __init__(self, continuous_dim, categorical_names, kernel=None, noise_var=1e-5):\n",
    "        \"\"\"\n",
    "        CoCaBO algorithm initialization\n",
    "        :param continuous_dim: Dimensionality of continuous variables\n",
    "        :param categorical_names: List of categorical names (e.g., ['omic1', 'omic2', ..., 'omic5'])\n",
    "        :param kernel: Kernel for the Gaussian Process (Matern kernel by default)\n",
    "        :param noise_var: Noise variance for Gaussian Process\n",
    "        \"\"\"\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.categorical_names = categorical_names\n",
    "        self.categorical_dim = len(categorical_names)  # Number of categorical arms\n",
    "        \n",
    "        # Initialize the kernel for Gaussian Process (Matern kernel)\n",
    "        self.kernel = kernel if kernel else Matern(length_scale=1.0, nu=1.5)  # Matern kernel with nu=1.5\n",
    "        \n",
    "        # Initialize the Gaussian Process Regressor\n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise_var)\n",
    "        \n",
    "        # Storage for past data\n",
    "        self.X_cont = []  # Stores continuous variables\n",
    "        self.X_cat = []   # Stores categorical variables (as indices)\n",
    "        self.y = []       # Stores corresponding objective function values\n",
    "        \n",
    "        # Initialize Multi-Armed Bandit (MAB) for categorical variable\n",
    "        self.mab_rewards = np.zeros(self.categorical_dim)  # Rewards for each categorical arm\n",
    "        self.mab_counts = np.zeros(self.categorical_dim)   # Count of pulls for each categorical arm\n",
    "    \n",
    "    def fit(self, X_cont, X_cat, y):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Process model on both continuous and categorical data.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param y: Objective function values (rewards)\n",
    "        \"\"\"\n",
    "        # Combine continuous and categorical data\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        \n",
    "        # Fit the Gaussian Process Regressor model\n",
    "        self.gpr.fit(X_combined, y)\n",
    "        \n",
    "        # Store the data for future optimization\n",
    "        self.X_cont.extend(X_cont)\n",
    "        self.X_cat.extend(X_cat)\n",
    "        self.y.extend(y)\n",
    "    \n",
    "    def predict(self, X_cont, X_cat):\n",
    "        \"\"\"\n",
    "        Predict mean and variance for new points.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :return: Mean and standard deviation from GP\n",
    "        \"\"\"\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        mean, std = self.gpr.predict(X_combined, return_std=True)\n",
    "        return mean, std\n",
    "    \n",
    "    def ucb(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound (UCB) acquisition function for continuous variables.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: UCB values\n",
    "        \"\"\"\n",
    "        mean, std = self.predict(X_cont, X_cat)\n",
    "        ucb_values = mean + kappa * std\n",
    "        return ucb_values\n",
    "    \n",
    "    def select_categorical_arm(self):\n",
    "        \"\"\"\n",
    "        Select the categorical arm using the best-performing arm (exploitation).\n",
    "        :return: Best categorical arm based on historical rewards\n",
    "        \"\"\"\n",
    "        # Select the categorical arm with the highest average reward\n",
    "        best_arm_idx = np.argmax(self.mab_rewards)\n",
    "        return self.categorical_names[best_arm_idx]  # Return the string name of the selected arm\n",
    "    \n",
    "    def update_mab(self, arm_idx, reward):\n",
    "        \"\"\"\n",
    "        Update the reward distribution of the Multi-Armed Bandit (MAB).\n",
    "        :param arm_idx: The index of the arm that was pulled\n",
    "        :param reward: The reward received for pulling the arm\n",
    "        \"\"\"\n",
    "        self.mab_counts[arm_idx] += 1\n",
    "        # Update the reward for the selected arm (simple average reward)\n",
    "        self.mab_rewards[arm_idx] = ((self.mab_counts[arm_idx] - 1) * self.mab_rewards[arm_idx] + reward) / self.mab_counts[arm_idx]\n",
    "    \n",
    "    def constant_liars_algorithm(self, X_cont, X_cat, n_predictions=5, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Constant Liar's Algorithm - Make multiple predictions using the GP and select the best-performing ones.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param n_predictions: Number of predictions to make\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values from the predictions\n",
    "        \"\"\"\n",
    "        best_predictions = []\n",
    "        \n",
    "        for i in range(n_predictions):\n",
    "            # Select categorical arm using MAB (best-performing arm based on reward distribution)\n",
    "            h_t = self.select_categorical_arm()\n",
    "            h_t_idx = self.categorical_names.index(h_t)  # Convert the arm name to its index\n",
    "            \n",
    "            # Predict UCB values for continuous and categorical variables\n",
    "            ucb_values = self.ucb(X_cont, np.full((X_cont.shape[0], 1), h_t_idx), kappa)\n",
    "            \n",
    "            best_idx = np.argmax(ucb_values)  # Select the index with the highest UCB value\n",
    "            best_cont = X_cont[best_idx]\n",
    "            best_cat = h_t\n",
    "            \n",
    "            # Append prediction results (continuous, categorical)\n",
    "            best_predictions.append((best_cont, best_cat, ucb_values[best_idx]))\n",
    "            \n",
    "            # Simulate querying the function and getting a new reward for the selected arm\n",
    "            ft = np.random.normal(loc=0.5, scale=0.2)  # Simulated reward\n",
    "            \n",
    "            # Update MAB and GP model with new data\n",
    "            self.update_mab(h_t_idx, ft)  # Update the MAB with the new reward\n",
    "            self.fit(np.array([best_cont]), np.array([[h_t_idx]]), np.array([ft]))  # Update the GP model\n",
    "            \n",
    "            print(f\"Prediction {i+1}: Best continuous: {best_cont}, Best categorical: {best_cat}, UCB value: {ucb_values[best_idx]}, Reward: {ft}\")\n",
    "        \n",
    "        # Print all predictions with corresponding UCB values\n",
    "        print(\"\\nPredictions with UCB values:\")\n",
    "        for cont, cat, ucb_value in best_predictions:\n",
    "            print(f\"Best continuous: {cont}, Best categorical: {cat}, UCB value: {ucb_value}\")\n",
    "        \n",
    "        # Return the best prediction (highest UCB)\n",
    "        return max(best_predictions, key=lambda x: x[2])[:2]\n",
    "\n",
    "    def optimize(self, X_cont, X_cat, n_predictions=5, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Optimize the acquisition function (UCB) and select the best continuous and categorical values.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param n_predictions: Number of predictions to make using constant liar's algorithm\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values\n",
    "        \"\"\"\n",
    "        # Apply the constant liar's algorithm to make n predictions\n",
    "        best_cont, best_cat = self.constant_liars_algorithm(X_cont, X_cat, n_predictions, kappa)\n",
    "        \n",
    "        # Return the best continuous and categorical pair\n",
    "        return best_cont, best_cat\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "np.random.seed(42)  # For reproducibility of results\n",
    "\n",
    "# Categorical names as strings\n",
    "categorical_names = ['omic1', 'omic2', 'omic3', 'omic4', 'omic5']\n",
    "\n",
    "# Example continuous and categorical variables (encoded as indices for MAB)\n",
    "X_cont = np.array([[0.5], [0.2], [0.7]])  # Example continuous variables\n",
    "X_cat = np.array([[0], [1], [2]])  # Example categorical variables (as indices)\n",
    "y = np.array([0.3, 0.7, 0.5])  # Objective values (rewards)\n",
    "\n",
    "# Instantiate the CoCaBO object with categorical names and Matern kernel\n",
    "optimizer = CoCaBO(continuous_dim=1, categorical_names=categorical_names)\n",
    "\n",
    "# Fit the model to the data\n",
    "optimizer.fit(X_cont, X_cat, y)\n",
    "\n",
    "# Predict UCB values for new points\n",
    "new_cont = np.array([[0.6], [0.3]])  # New continuous points to evaluate\n",
    "new_cat = np.array([[1], [0]])  # New categorical points (encoded as indices)\n",
    "\n",
    "# Optimize to get the best combination of continuous and categorical variables\n",
    "best_cont, best_cat = optimizer.optimize(new_cont, new_cat, n_predictions=5)\n",
    "print(f\"\\nBest continuous: {best_cont}, Best categorical: {best_cat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some softmax based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: Best continuous: [0.6], Best categorical: omic2, UCB value: 0.8510456065515916, Reward: 0.27762397639061587\n",
      "Prediction 2: Best continuous: [0.3], Best categorical: omic1, UCB value: 1.90326688006542, Reward: 0.5637804369378767\n",
      "Prediction 3: Best continuous: [0.6], Best categorical: omic1, UCB value: 1.3655049452101133, Reward: 0.5558082584400276\n",
      "Prediction 4: Best continuous: [0.6], Best categorical: omic4, UCB value: 2.017893659580081, Reward: 0.7021030569613053\n",
      "Prediction 5: Best continuous: [0.6], Best categorical: omic1, UCB value: 2.022913458382277, Reward: 0.383824373195297\n",
      "\n",
      "Predictions with UCB values:\n",
      "Best continuous: [0.6], Best categorical: omic2, UCB value: 0.8510456065515916\n",
      "Best continuous: [0.3], Best categorical: omic1, UCB value: 1.90326688006542\n",
      "Best continuous: [0.6], Best categorical: omic1, UCB value: 1.3655049452101133\n",
      "Best continuous: [0.6], Best categorical: omic4, UCB value: 2.017893659580081\n",
      "Best continuous: [0.6], Best categorical: omic1, UCB value: 2.022913458382277\n",
      "\n",
      "Best continuous: [0.6], Best categorical: omic1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "class CoCaBO:\n",
    "    def __init__(self, continuous_dim, categorical_names, kernel=None, noise_var=1e-5, tau=1.0):\n",
    "        \"\"\"\n",
    "        CoCaBO algorithm initialization\n",
    "        :param continuous_dim: Dimensionality of continuous variables\n",
    "        :param categorical_names: List of categorical names (e.g., ['omic1', 'omic2', ..., 'omic5'])\n",
    "        :param kernel: Kernel for the Gaussian Process (Matern kernel by default)\n",
    "        :param noise_var: Noise variance for Gaussian Process\n",
    "        :param tau: Softmax temperature parameter (controls exploration-exploitation)\n",
    "        \"\"\"\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.categorical_names = categorical_names\n",
    "        self.categorical_dim = len(categorical_names)  # Number of categorical arms\n",
    "        \n",
    "        # Initialize the kernel for Gaussian Process (Matern kernel)\n",
    "        self.kernel = kernel if kernel else Matern(length_scale=1.0, nu=1.5)  # Matern kernel with nu=1.5\n",
    "        \n",
    "        # Initialize the Gaussian Process Regressor\n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise_var)\n",
    "        \n",
    "        # Storage for past data\n",
    "        self.X_cont = []  # Stores continuous variables\n",
    "        self.X_cat = []   # Stores categorical variables (as indices)\n",
    "        self.y = []       # Stores corresponding objective function values\n",
    "        \n",
    "        # Initialize Multi-Armed Bandit (MAB) for categorical variable\n",
    "        self.mab_rewards = np.zeros(self.categorical_dim)  # Rewards for each categorical arm\n",
    "        self.mab_counts = np.zeros(self.categorical_dim)   # Count of pulls for each categorical arm\n",
    "        self.tau = tau  # Softmax temperature for exploration-exploitation trade-off\n",
    "    \n",
    "    def fit(self, X_cont, X_cat, y):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Process model on both continuous and categorical data.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param y: Objective function values (rewards)\n",
    "        \"\"\"\n",
    "        # Combine continuous and categorical data\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        \n",
    "        # Fit the Gaussian Process Regressor model\n",
    "        self.gpr.fit(X_combined, y)\n",
    "        \n",
    "        # Store the data for future optimization\n",
    "        self.X_cont.extend(X_cont)\n",
    "        self.X_cat.extend(X_cat)\n",
    "        self.y.extend(y)\n",
    "    \n",
    "    def predict(self, X_cont, X_cat):\n",
    "        \"\"\"\n",
    "        Predict mean and variance for new points.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :return: Mean and standard deviation from GP\n",
    "        \"\"\"\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        mean, std = self.gpr.predict(X_combined, return_std=True)\n",
    "        return mean, std\n",
    "    \n",
    "    def ucb(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound (UCB) acquisition function for continuous variables.\n",
    "        :param X_cont: Continuous variables\n",
    "        :param X_cat: Categorical variables (as indices)\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: UCB values\n",
    "        \"\"\"\n",
    "        mean, std = self.predict(X_cont, X_cat)\n",
    "        ucb_values = mean + kappa * std\n",
    "        return ucb_values\n",
    "    \n",
    "    def softmax_arm_selection(self):\n",
    "        \"\"\"\n",
    "        Select the categorical arm using softmax-based exploration-exploitation.\n",
    "        :return: Best categorical arm based on softmax selection\n",
    "        \"\"\"\n",
    "        # Compute softmax probabilities for each arm based on rewards\n",
    "        exp_rewards = np.exp(self.mab_rewards / self.tau)\n",
    "        softmax_probs = exp_rewards / np.sum(exp_rewards)\n",
    "        \n",
    "        # Sample an arm based on softmax probabilities (exploration-exploitation balance)\n",
    "        arm_idx = np.random.choice(self.categorical_dim, p=softmax_probs)\n",
    "        return self.categorical_names[arm_idx]  # Return the string name of the selected arm\n",
    "    \n",
    "    def update_mab(self, arm_idx, reward):\n",
    "        \"\"\"\n",
    "        Update the reward distribution of the Multi-Armed Bandit (MAB).\n",
    "        :param arm_idx: The index of the arm that was pulled\n",
    "        :param reward: The reward received for pulling the arm\n",
    "        \"\"\"\n",
    "        self.mab_counts[arm_idx] += 1\n",
    "        # Update the reward for the selected arm (simple average reward)\n",
    "        self.mab_rewards[arm_idx] = ((self.mab_counts[arm_idx] - 1) * self.mab_rewards[arm_idx] + reward) / self.mab_counts[arm_idx]\n",
    "    \n",
    "    def constant_liars_algorithm(self, X_cont, X_cat, n_predictions=5, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Constant Liar's Algorithm - Make multiple predictions using the GP and select the best-performing ones.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param n_predictions: Number of predictions to make\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values from the predictions\n",
    "        \"\"\"\n",
    "        best_predictions = []\n",
    "        \n",
    "        for i in range(n_predictions):\n",
    "            # Select categorical arm using softmax (exploration-exploitation balance)\n",
    "            h_t = self.softmax_arm_selection()\n",
    "            h_t_idx = self.categorical_names.index(h_t)  # Convert the arm name to its index\n",
    "            \n",
    "            # Predict UCB values for continuous and categorical variables\n",
    "            ucb_values = self.ucb(X_cont, np.full((X_cont.shape[0], 1), h_t_idx), kappa)\n",
    "            \n",
    "            best_idx = np.argmax(ucb_values)  # Select the index with the highest UCB value\n",
    "            best_cont = X_cont[best_idx]\n",
    "            best_cat = h_t\n",
    "            \n",
    "            # Append prediction results (continuous, categorical)\n",
    "            best_predictions.append((best_cont, best_cat, ucb_values[best_idx]))\n",
    "            \n",
    "            # Simulate querying the function and getting a new reward for the selected arm\n",
    "            ft = np.random.normal(loc=0.5, scale=0.2)  # Simulated reward\n",
    "            \n",
    "            # Update MAB and GP model with new data\n",
    "            self.update_mab(h_t_idx, ft)  # Update the MAB with the new reward\n",
    "            self.fit(np.array([best_cont]), np.array([[h_t_idx]]), np.array([ft]))  # Update the GP model\n",
    "            \n",
    "            print(f\"Prediction {i+1}: Best continuous: {best_cont}, Best categorical: {best_cat}, UCB value: {ucb_values[best_idx]}, Reward: {ft}\")\n",
    "        \n",
    "        # Print all predictions with corresponding UCB values\n",
    "        print(\"\\nPredictions with UCB values:\")\n",
    "        for cont, cat, ucb_value in best_predictions:\n",
    "            print(f\"Best continuous: {cont}, Best categorical: {cat}, UCB value: {ucb_value}\")\n",
    "        \n",
    "        # Return the best prediction (highest UCB)\n",
    "        return max(best_predictions, key=lambda x: x[2])[:2]\n",
    "\n",
    "    def optimize(self, X_cont, X_cat, n_predictions=5, kappa=2.0):\n",
    "        \"\"\"\n",
    "        Optimize the acquisition function (UCB) and select the best continuous and categorical values.\n",
    "        :param X_cont: New continuous points to evaluate\n",
    "        :param X_cat: New categorical points\n",
    "        :param n_predictions: Number of predictions to make using constant liar's algorithm\n",
    "        :param kappa: Exploration parameter for UCB\n",
    "        :return: Best continuous and categorical values\n",
    "        \"\"\"\n",
    "        # Apply the constant liar's algorithm to make n predictions\n",
    "        best_cont, best_cat = self.constant_liars_algorithm(X_cont, X_cat, n_predictions, kappa)\n",
    "        \n",
    "        # Return the best continuous and categorical pair\n",
    "        return best_cont, best_cat\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "np.random.seed(42)  # For reproducibility of results\n",
    "\n",
    "# Categorical names as strings\n",
    "categorical_names = ['omic1', 'omic2', 'omic3', 'omic4', 'omic5']\n",
    "\n",
    "# Example continuous and categorical variables (encoded as indices for MAB)\n",
    "X_cont = np.array([[0.5], [0.2], [0.7]])  # Example continuous variables\n",
    "X_cat = np.array([[0], [1], [2]])  # Example categorical variables (as indices)\n",
    "y = np.array([0.3, 0.7, 0.5])  # Objective values (rewards)\n",
    "\n",
    "# Instantiate the CoCaBO object with categorical names and Matern kernel\n",
    "optimizer = CoCaBO(continuous_dim=1, categorical_names=categorical_names)\n",
    "\n",
    "# Fit the model to the data\n",
    "optimizer.fit(X_cont, X_cat, y)\n",
    "\n",
    "# Predict UCB values for new points\n",
    "new_cont = np.array([[0.6], [0.3]])  # New continuous points to evaluate\n",
    "new_cat = np.array([[1], [0]])  # New categorical points (encoded as indices)\n",
    "\n",
    "# Optimize to get the best combination of continuous and categorical variables\n",
    "best_cont, best_cat = optimizer.optimize(new_cont, new_cat, n_predictions=5)\n",
    "print(f\"\\nBest continuous: {best_cont}, Best categorical: {best_cat}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
